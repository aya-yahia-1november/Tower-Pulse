{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8665573e-c96a-43bb-89d2-6642c0a632b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp, round, current_timestamp\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed11b92-b0d0-417d-b07b-0024e56e7894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark Session Created Successfully!\n",
      "Spark Version: 4.0.1\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TelecomTowerStreaming\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,\"\n",
    "        \"com.datastax.spark:spark-cassandra-connector_2.13:3.4.1\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.sql.streaming.minBatchesToRetain\", \"2\") \\\n",
    "    .config(\"spark.cleaner.referenceTracking.cleanCheckpoints\", \"true\") \\\n",
    "    .config(\"spark.sql.streaming.schemaInference\", \"false\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation.cleanup.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"✅ Spark Session Created Successfully!\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c293ba-0bb9-4644-ad8d-4053b6305c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.cassandra.connection.host\", \"cassandra\")  # عدلي حسب IP أو Docker host\n",
    "spark.conf.set(\"spark.cassandra.connection.port\", \"9042\")\n",
    "spark.conf.set(\"spark.cassandra.output.concurrent.writes\", \"5\")\n",
    "spark.conf.set(\"spark.cassandra.output.batch.size.rows\", \"500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbbe7c8-3b74-4887-9ace-3d5e8493c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_schema = StructType([\n",
    "    StructField(\"tower_id\", LongType(), True),\n",
    "    StructField(\"CID\", LongType(), True),\n",
    "    StructField(\"TAC\", LongType(), True),\n",
    "    StructField(\"radio\", StringType(), True),\n",
    "    StructField(\"MCC\", IntegerType(), True),\n",
    "    StructField(\"MNC\", IntegerType(), True),\n",
    "    StructField(\"Network\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"governorate_en\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"RANGE\", IntegerType(), True),\n",
    "    StructField(\"SAM\", IntegerType(), True),\n",
    "    StructField(\"tower_status\", StringType(), True),\n",
    "    StructField(\"signal_quality\", StringType(), True),\n",
    "    StructField(\"coverage_gap\", BooleanType(), True),\n",
    "    StructField(\"priority\", StringType(), True),\n",
    "    StructField(\"signal_strength\", IntegerType(), True),\n",
    "    StructField(\"speed\", DoubleType(), True),\n",
    "    StructField(\"latency\", DoubleType(), True),\n",
    "    StructField(\"QoE\", DoubleType(), True),\n",
    "    StructField(\"avg_load\", DoubleType(), True),\n",
    "    StructField(\"total_calls\", IntegerType(), True),\n",
    "    StructField(\"drop_calls\", IntegerType(), True),\n",
    "    StructField(\"drop_rate\", DoubleType(), True),\n",
    "    StructField(\"maintenance_type\", StringType(), True),\n",
    "    StructField(\"labor_cost_egp\", DoubleType(), True),\n",
    "    StructField(\"parts_cost_egp\", DoubleType(), True),\n",
    "    StructField(\"downtime_hours\", DoubleType(), True),\n",
    "    StructField(\"vendor\", StringType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"created\", LongType(), True),\n",
    "    StructField(\"updated\", LongType(), True),\n",
    "    StructField(\"created_dt\", StringType(), True),\n",
    "    StructField(\"updated_dt\", StringType(), True),\n",
    "    StructField(\"maintenance_date\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe805319-8250-4649-a6f5-88ed9af5c4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kafka Stream Connected\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"/tmp/checkpoints/telecom_v1\"\n",
    "\n",
    "df_raw = (\n",
    "    spark\n",
    "        .readStream\n",
    "        .format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\")\n",
    "        .option(\"subscribe\", \"telecom-stream\")\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .option(\"maxOffsetsPerTrigger\", \"5000\")\n",
    "        .option(\"kafka.group.id\", \"spark_telecom_group\")\n",
    "        .option(\"failOnDataLoss\", \"false\")\n",
    "        .load()\n",
    ")\n",
    "\n",
    "print(\"✅ Kafka Stream Connected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbe30dc-b09a-4d95-a467-cf297d5548ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tower_id: long (nullable = true)\n",
      " |-- CID: long (nullable = true)\n",
      " |-- TAC: long (nullable = true)\n",
      " |-- radio: string (nullable = true)\n",
      " |-- MCC: integer (nullable = true)\n",
      " |-- MNC: integer (nullable = true)\n",
      " |-- Network: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- governorate_en: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- RANGE: integer (nullable = true)\n",
      " |-- SAM: integer (nullable = true)\n",
      " |-- tower_status: string (nullable = true)\n",
      " |-- signal_quality: string (nullable = true)\n",
      " |-- coverage_gap: boolean (nullable = true)\n",
      " |-- priority: string (nullable = true)\n",
      " |-- signal_strength: integer (nullable = true)\n",
      " |-- speed: double (nullable = true)\n",
      " |-- latency: double (nullable = true)\n",
      " |-- QoE: double (nullable = true)\n",
      " |-- avg_load: double (nullable = true)\n",
      " |-- total_calls: integer (nullable = true)\n",
      " |-- drop_calls: integer (nullable = true)\n",
      " |-- drop_rate: double (nullable = true)\n",
      " |-- maintenance_type: string (nullable = true)\n",
      " |-- labor_cost_egp: double (nullable = true)\n",
      " |-- parts_cost_egp: double (nullable = true)\n",
      " |-- downtime_hours: double (nullable = true)\n",
      " |-- vendor: string (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- created: long (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- created_dt: string (nullable = true)\n",
      " |-- updated_dt: string (nullable = true)\n",
      " |-- maintenance_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Parse and Transform Data\n",
    "df_parsed = df_raw.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), tower_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "df_parsed.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea6016a-ece4-4f5f-95f6-e3c5053a9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1c – Define Checkpoints for Streams\n",
    "checkpoint_dir_console = \"/tmp/checkpoints/console\"\n",
    "checkpoint_dir_memory = \"/tmp/checkpoints/memory\"\n",
    "checkpoint_dir_cassandra = \"/tmp/checkpoints/cassandra_stream_v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64baa73e-3077-4662-ba15-8a272c032553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "rename_dict = {\n",
    "    \"tower_id\": \"tower_id\",\n",
    "    \"radio\": \"radio\",\n",
    "    \"MCC\": \"mobile_country_code\",\n",
    "    \"MNC\": \"mobile_network_code\",\n",
    "    \"TAC\": \"tracking_area_code\",\n",
    "    \"CID\": \"cell_id\",\n",
    "    \"longitude\": \"longitude\",\n",
    "    \"latitude\": \"latitude\",\n",
    "    \"RANGE\": \"range\",\n",
    "    \"SAM\": \"sampling_count\",\n",
    "    \"created\": \"created\",\n",
    "    \"updated\": \"updated\",\n",
    "    \"governorate_en\": \"governorate_en\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Network\": \"network\",\n",
    "    \"drop_calls\": \"drop_calls\",\n",
    "    \"total_calls\": \"total_calls\",\n",
    "    \"drop_rate\": \"drop_rate\",\n",
    "    \"avg_load\": \"avg_load\",\n",
    "    \"signal_strength\": \"signal_strength\",\n",
    "    \"speed\": \"speed\",\n",
    "    \"latency\": \"latency\",\n",
    "    \"QoE\": \"quality_of_experience\",\n",
    "    \"coverage_gap\": \"coverage_gap\",\n",
    "    \"signal_quality\": \"signal_quality\",\n",
    "    \"tower_status\": \"tower_status\",\n",
    "    \"priority\": \"priority\",\n",
    "    \"maintenance_type\": \"maintenance_type\",\n",
    "    \"created_dt\": \"created_dt\",\n",
    "    \"updated_dt\": \"updated_dt\",\n",
    "    \"maintenance_date\": \"maintenance_date\",\n",
    "    \"labor_cost_egp\": \"labor_cost_egp\",\n",
    "    \"parts_cost_egp\": \"parts_cost_egp\",\n",
    "    \"downtime_hours\": \"downtime_hours\",\n",
    "    \"vendor\": \"vendor\",\n",
    "    \"notes\": \"notes\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9118595-94f9-4d8d-8a37-c4534bf39ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df_parsed\n",
    "for old, new in rename_dict.items():\n",
    "    df_renamed = df_renamed.withColumnRenamed(old, new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3093e529-6e98-474c-9c8b-c49d92bdb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Transformation Applied\n"
     ]
    }
   ],
   "source": [
    "# STEP 4c: Enrichment\n",
    "df_enriched = df_renamed \\\n",
    "    .withColumn(\"maint_total_cost\", col(\"labor_cost_egp\") + col(\"parts_cost_egp\")) \\\n",
    "    .withColumn(\"is_high_risk\", \n",
    "        (col(\"drop_rate\") > 0.02) | \n",
    "        (col(\"signal_strength\") < -95) | \n",
    "        (col(\"latency\") > 150)) \\\n",
    "    .withColumn(\"updated_dt\", to_timestamp(col(\"updated_dt\"))) \\\n",
    "    .withColumn(\"created_dt\", to_timestamp(col(\"created_dt\"))) \\\n",
    "    .withColumn(\"is_anomaly\",\n",
    "        (col(\"drop_rate\") > 0.1) |\n",
    "        (col(\"latency\") > 300) |\n",
    "        (col(\"speed\") < 1)) \\\n",
    "    .withColumn(\"lat_rounded\", round(col(\"latitude\"), 3)) \\\n",
    "    .withColumn(\"lon_rounded\", round(col(\"longitude\"), 3))\n",
    "\n",
    "print(\"✅ Data Transformation Applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b14830-d7eb-4378-af09-88b039ca2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Console Stream — تأكيد وصول البيانات\n",
    "console_query = df_enriched.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir_console) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9b6328-d18a-4185-a80a-bc6f5afc6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Memory table stream started: live_towers_view\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Memory Table Stream\n",
    "df_with_watermark = df_enriched.withWatermark(\"updated_dt\", \"5 minutes\")\n",
    "query_memory = df_with_watermark.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"live_towers_view\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()\n",
    "\n",
    "print(\"✅ Memory table stream started: live_towers_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64dc78b5-aa6b-4d51-854a-cc8dd79aa7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parquet Stream Started\n"
     ]
    }
   ],
   "source": [
    "query_parquet = df_enriched.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"/tmp/telecom_output\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()\n",
    "\n",
    "print(\"✅ Parquet Stream Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4ab614-99f3-47fa-bb97-4a7b5ad34d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cassandra Stream Started\n",
      "Batch 0 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 0 written successfully\n",
      "Batch 1 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 1 written successfully\n",
      "Batch 2 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 2 written successfully\n",
      "Batch 3 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 3 written successfully\n",
      "Batch 4 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 4 written successfully\n",
      "Batch 5 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 5 written successfully\n",
      "Batch 6 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 6 written successfully\n",
      "Batch 7 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 7 written successfully\n",
      "Batch 8 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 8 written successfully\n",
      "Batch 9 contains 5000 rows — writing to Cassandra\n",
      "✅ Batch 9 written successfully\n",
      "Batch 10 contains 5000 rows — writing to Cassandra\n"
     ]
    }
   ],
   "source": [
    "def write_to_cassandra(batch_df, batch_id):\n",
    "    batch_count = batch_df.count()\n",
    "    if batch_count > 0:\n",
    "        print(f\"Batch {batch_id} contains {batch_count} rows — writing to Cassandra\")\n",
    "        batch_df.write \\\n",
    "            .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .option(\"table\", \"tower_metrics\") \\\n",
    "            .option(\"keyspace\", \"telecom\") \\\n",
    "            .save()\n",
    "        print(f\"✅ Batch {batch_id} written successfully\")\n",
    "    else:\n",
    "        print(f\"Batch {batch_id} is empty — skipping\")\n",
    "\n",
    "query_cassandra = df_enriched.writeStream \\\n",
    "    .foreachBatch(write_to_cassandra) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_dir_cassandra) \\\n",
    "    .start()\n",
    "\n",
    "print(\"✅ Cassandra Stream Started\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "297cfbc0-517f-483a-a421-58c0b998c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping query: None\n",
      "Stopping query: live_towers_view\n",
      "Stopping query: None\n",
      "Stopping query: None\n"
     ]
    }
   ],
   "source": [
    "for q in spark.streams.active:\n",
    "    print(f\"Stopping query: {q.name}\")\n",
    "    q.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb31d606-7a86-4dd0-b7b8-0a8704a6c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a463c-069c-48d2-bfb0-8d4df312c764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d60430-4572-4b40-9eb4-a270dcfac2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
